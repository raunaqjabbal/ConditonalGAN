{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raunaqjabbal/ConditonalGAN/blob/main/Conditional_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0OwpFl8JIxP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3nvoSP3Btzu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.layers import Layer\n",
        "from keras.models import Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import InputLayer\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import ReLU\n",
        "from keras import activations\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Normalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.activations import sigmoid\n",
        "from keras.activations import selu\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train) ,(X_test, y_test)  = tf.keras.datasets.mnist.load_data()\n",
        "X = np.append(X_train,X_test,axis=0)\n",
        "y = np.append(y_train,y_test,axis=0)\n",
        "\n",
        "del X_train,y_train,X_test,y_test\n",
        "\n",
        "X = X[...,np.newaxis]\n",
        "# norm_layer = Normalization(mean=(0.5),variance=np.square(0.5))\n",
        "X = X.astype(\"float32\") / 255.0\n",
        "# X = (X*2)-1\n",
        "\n",
        "\n",
        "Z_DIM = 128\n",
        "DEPTH = len(np.unique(y))\n",
        "CHANNELS = 1\n",
        "IMGSIZE = 28\n",
        "BATCH_SIZE=32\n",
        "\n",
        "y=tf.one_hot(y,DEPTH)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "-xXxkPk1hsXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(Layer):\n",
        "    def __init__(self, filters=64, strides=2,kernel_size=3,final_layer=False,**kwargs):\n",
        "        super(Generator, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.strides  =strides\n",
        "        self.kernel_size= kernel_size\n",
        "        self.final_layer=final_layer\n",
        "        self.weight_initer = tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
        "        self.conv2dt = Conv2DTranspose(filters,kernel_size,strides)\n",
        "        self.norm= BatchNormalization()\n",
        "        if self.final_layer:\n",
        "          self.activ = Activation(sigmoid)\n",
        "        else:  \n",
        "          self.activ = Activation(selu)\n",
        "          \n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv2dt(x)\n",
        "        if not self.final_layer:\n",
        "          x = self.norm(x)\n",
        "        x = self.activ(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "g7q51_dSjVAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(1,1,DEPTH+Z_DIM))\n",
        "# x = Flatten()(input)\n",
        "# x = Dense(1 * 1 * (DEPTH+Z_DIM))(x)\n",
        "# x = Activation(selu)(x)\n",
        "# x = Reshape((1, 1, DEPTH+Z_DIM))(x)\n",
        "\n",
        "\n",
        "# x = Generator(256)(x)\n",
        "# # x = Flatten()(x)\n",
        "# # x = Dense(3 * 3 * (256))(x)\n",
        "# # x = LeakyReLU(alpha=0.2)(x)\n",
        "# # x = Reshape((3, 3, 256))(x)\n",
        "\n",
        "# x = Generator(128, kernel_size=4, strides=1)(x)\n",
        "# # x = Flatten()(x)\n",
        "# # x = Dense(6 * 6 * (128))(x)\n",
        "# # x = LeakyReLU(alpha=0.2)(x)\n",
        "# # x = Reshape((6, 6, 128))(x)\n",
        "\n",
        "# x = Generator(64) (x)\n",
        "# x = Flatten()(x)\n",
        "# x = Dense(13 * 13 * (64))(x)\n",
        "# x = Activation(selu)(x)\n",
        "# x = Reshape((13, 13, 64))(x)\n",
        "# x = Generator(1,kernel_size=4, final_layer=True)(x)\n",
        "\n",
        "\n",
        "x = Dense(7 * 7 * (DEPTH+Z_DIM))(input)\n",
        "x = Activation(selu)(x)\n",
        "x = Reshape((7, 7, DEPTH+Z_DIM))(x)\n",
        "x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = Activation(selu)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
        "x = Activation(selu)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(1, (3, 3), padding=\"same\", activation=\"sigmoid\")(x)\n",
        "\n",
        "Activation(selu)\n",
        "\n",
        "generator= Model(inputs=input, outputs=x)\n",
        "\n",
        "\n",
        "# generator.summary()\n",
        "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64, expand_nested=True)"
      ],
      "metadata": {
        "id": "azNLz5lFxktI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Layer):\n",
        "    def __init__(self, filters=64, strides=2,kernel_size=4,final_layer=False,**kwargs):\n",
        "        super(Discriminator, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.strides  =strides\n",
        "        self.kernel_size= kernel_size\n",
        "        self.final_layer=final_layer\n",
        "        self.weight_initer = tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
        "\n",
        "        self.conv2d = Conv2D(filters,kernel_size,strides)\n",
        "        self.norm= BatchNormalization()\n",
        "        self.activ = Activation(selu)\n",
        "        self.flat = Flatten()\n",
        "          \n",
        "    def call(self, x):\n",
        "        x = self.conv2d(x)\n",
        "        if not self.final_layer:\n",
        "          x = self.norm(x)\n",
        "          x = self.activ(x)\n",
        "        else:\n",
        "          x = self.flat(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "V0PpFZuDK3F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(28,28,DEPTH+CHANNELS))\n",
        "# x = Discriminator(64)(input)\n",
        "# x = Discriminator(128)(x)\n",
        "# x = Discriminator(1, final_layer=True)(x)\n",
        "\n",
        "# x = Discriminator(1, final_layer=True)(input)\n",
        "# x = Dense(1)(x)\n",
        "\n",
        "\n",
        "x = Conv2D(64, (5,5), strides=(2, 2), padding=\"same\")(input)\n",
        "x = Activation(selu)(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\")(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Activation(selu)(x)\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "x = Dense(1)(x)\n",
        "\n",
        "discriminator = Model(inputs=input, outputs=x)\n",
        "\n",
        "# discriminator.summary()\n",
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64, expand_nested=True)"
      ],
      "metadata": {
        "id": "9eIqDET4LVIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxy_M7xbQef-"
      },
      "source": [
        "## Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg_4z8-glz6P"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "import torch\n",
        "def plot_results(images, size=8):\n",
        "    # display.clear_output(wait=False)\n",
        "    photos = (images[:size*size,:,:,:CHANNELS])\n",
        "    photos = np.transpose(photos, (0, 3, 1, 2)) \n",
        "    image_grid = make_grid(torch.tensor(photos), nrow=size)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze(),cmap='gray')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "def repeatlabels(labels):\n",
        "    demo = labels[:,None,None,:] \n",
        "    demo = tf.repeat(labels, IMGSIZE, axis=1)\n",
        "    demo = tf.repeat(demo, IMGSIZE, axis=2)\n",
        "    return demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X25T2kUJIxT"
      },
      "source": [
        "## Build and compile the GAN model\n",
        "\n",
        "- Build the sequential model for the GAN, passing a list containing the generator and discriminator.\n",
        "- Compile the model with a binary cross entropy loss and rmsprop optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuV97d_kCpb_"
      },
      "outputs": [],
      "source": [
        "def GAN(gan, X, y, n_epochs=50):\n",
        "    generator, discriminator = gan\n",
        "    labels_set = y[:,None,None,:]\n",
        "    labels_repeated_set = repeatlabels(labels_set)                                                \n",
        "\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))       \n",
        "        loss_gen=[]\n",
        "        loss_dis=[]\n",
        "        for i in range(X.shape[0]//BATCH_SIZE):\n",
        "            images = X[i*BATCH_SIZE:(i+1)*BATCH_SIZE,...]                          \n",
        "            labels = labels_set[i*BATCH_SIZE:(i+1)*BATCH_SIZE,...]\n",
        "            labels_repeated = labels_repeated_set[i*BATCH_SIZE:(i+1)*BATCH_SIZE,...]    \n",
        "\n",
        "###################################################################################################################################################\n",
        "            \n",
        "            noise = tf.random.normal(shape=(BATCH_SIZE, Z_DIM))[:,None,None,:]          \n",
        "            noise = tf.concat([noise, labels], axis=3)                                 \n",
        "            fake_images = generator(noise)                                              \n",
        "            \n",
        "            fake_images = tf.concat([fake_images, labels_repeated], axis=3)           \n",
        "            real_images = tf.concat([images, labels_repeated], axis=3) \n",
        "            mixed_images = tf.concat([fake_images, real_images], axis=0)\n",
        "            true_labels = tf.concat([tf.ones((BATCH_SIZE, 1)), tf.zeros((BATCH_SIZE, 1))], axis=0)\n",
        "\n",
        "            # discriminator.trainable = True\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                mixed_pred = discriminator(mixed_images)\n",
        "                loss = bceloss(true_labels,mixed_pred)\n",
        "                loss_dis.append(loss)\n",
        "            gradients = tape.gradient(loss,discriminator.trainable_weights)\n",
        "            optimizer1.apply_gradients(zip(gradients, discriminator.trainable_weights))      \n",
        "\n",
        "###################################################################################################################################################\n",
        "            \n",
        "            # discriminator.trainable = False\n",
        "\n",
        "            noise = tf.random.normal(shape=(BATCH_SIZE, Z_DIM))[:,None,None,:]          \n",
        "            noise = tf.concat([noise, labels], axis=3)             \n",
        "            with tf.GradientTape() as tape:             \n",
        "                fake_images = generator(noise)                                          \n",
        "                fake_images = tf.concat([fake_images, labels_repeated], axis=3)        \n",
        "                fake_pred = discriminator(fake_images)\n",
        "                loss = bceloss(tf.zeros_like(fake_pred),fake_pred)\n",
        "                loss_gen.append(loss)\n",
        "            gradients = tape.gradient(loss,generator.trainable_weights)\n",
        "            optimizer2.apply_gradients(zip(gradients, generator.trainable_weights))\n",
        "\n",
        "###################################################################################################################################################\n",
        "\n",
        "        plt.plot(range(X.shape[0]//BATCH_SIZE), loss_gen,label=\"Generator Loss\")\n",
        "        plt.plot(range(X.shape[0]//BATCH_SIZE), loss_dis,label=\"Discriminator Loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        plot_results(fake_images) \n",
        "    return fake_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzbX3hwKJIxW"
      },
      "source": [
        "### Run the training\n",
        "\n",
        "For each epoch, a set of 31 images will be displayed onscreen. The longer you train, the better your output fake images will be. You will pick your best images to submit to the grader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYx9rzdACt0A"
      },
      "outputs": [],
      "source": [
        "bceloss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer1 = tf.keras.optimizers.Adam(0.0003)\n",
        "optimizer2 = tf.keras.optimizers.Adam(0.0003)\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE=128\n",
        "\n",
        "X=X[:X.shape[0]//BATCH_SIZE*BATCH_SIZE,...]\n",
        "y=y[:y.shape[0]//BATCH_SIZE*BATCH_SIZE,...]\n",
        "\n",
        "# run the training loop and collect images\n",
        "fake_images=GAN([generator, discriminator], X, y, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rpYSgoKck70Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator.save_weights(\"/content/drive/MyDrive/gen.h5\")\n",
        "# discriminator.save_weights(\"/content/drive/MyDrive/dis.h5\")\n",
        "\n",
        "generator.load_weights(\"/content/drive/MyDrive/gen.h5\")\n",
        "discriminator.load_weights(\"/content/drive/MyDrive/dis.h5\")"
      ],
      "metadata": {
        "id": "ABt7eh4rUG_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_class(first_number, second_number, num=9):\n",
        "      \n",
        "    noise = tf.random.normal(shape=(1, Z_DIM))\n",
        "    noise = np.squeeze([noise]*num)\n",
        "    \n",
        "    first_label = tf.one_hot([first_number], DEPTH)\n",
        "    second_label = tf.one_hot([second_number], DEPTH)\n",
        "\n",
        "    percent_second_label = tf.linspace(0, 1, num)[:, None]\n",
        "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
        "    labels = first_label * (1.0 - percent_second_label) + second_label * percent_second_label\n",
        "\n",
        "    noise_and_labels = tf.concat([noise, labels], 1)[:,None,None,:]\n",
        "    fake = generator.predict(noise_and_labels)\n",
        "    return fake\n",
        "\n",
        "num = 64\n",
        "start_class = 6\n",
        "end_class = 9\n",
        "\n",
        "fake_images = interpolate_class(start_class, end_class, num)\n",
        "\n",
        "plot_results(fake_images,8)"
      ],
      "metadata": {
        "id": "rS6WdRLHlWiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}